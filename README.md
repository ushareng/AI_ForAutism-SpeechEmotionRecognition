### Problem Statement :

Inferring emotions from multiple modalities is very critical for social communication and deficits in emotion recognition are a very important marker in the diagnosis of autism spectrum disorder. This project uses AI to help autistic individuals recognize emotions in speech.

### Model :

tf-wav2vec2-base (Keras and Keras Core)

### Dataset : 

RAVDESS dataset (Ryerson Audio-Visual Database of Emotional Speech and Song) contains 7,356 audio files which are labeled against different emotions in Speech (calm, happy, sad, angry, fearful, surprise, and disgust expressions) and song (calm, happy, sad, angry, and fearful emotions). This dataset contains a sample of the files from the original RAVDESS dataset.

[RAVDESS](https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio)

HuggingFace spaces Demo: https://huggingface.co/spaces/tensorgirl/audio_classification

### References :

[huggingFace - tf-wav2vec2-base](https://huggingface.co/vasudevgupta/tf-wav2vec2-base)

[Official Keras Core Documentation](https://keras.io/keras_core/)

[RAVDESS](https://zenodo.org/record/1188976#.YFZuJ0j7SL8)

### My Advocacy in Autism

#### NeuroAI 

https://humansofdata.atlan.com/2019/08/unravel-the-mystery-of-the-human-brain-at-neuroai/

#### Neurodiversity India Summit 

[2022](https://neuroaiworld.com/neurodiversity-india-summit-2022/)
[2021](https://neuroaiworld.com/neurodiversity-india-summit-2021/)
[2020](https://neuroaiworld.com/neurodiversity-india-summit-2020/)


